{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this unit, I will discuss Bayesian posterior inference. I will\n",
    "explain Bayes rule, and explain how it can be used in data applications.\n",
    "Then, using data generated from a normal distribution, I will demonstrate\n",
    "how to use Bayes rule to calculate a distribution of the mean. I will\n",
    "list major assumptions of the approach at the end. \n",
    "\n",
    "Derived from statistical theory, Bayes rule is given by:\n",
    "\\begin{align*}\n",
    "Pr(A|B)= & \\frac{Pr(B|A)Pr(A)}{Pr(B)}\n",
    "\\end{align*}\n",
    "\n",
    "$Pr(A|B)$ is called the conditional probability of $A$ given $B$.\n",
    "Suppose two random events $A$ and $B$. The rule states that if event\n",
    "$B$ happened, I can calculate the probability of $A$ , $Pr(A|B)$\n",
    ", happening as follows: I multiply probability of $A$ happening given\n",
    "that $B$ happened, $Pr(B|A)$, with the probability of event $A$\n",
    "happening in general, $Pr(A)$. I divide the multiplication of both\n",
    "terms by the probability of $B$ happening in general, $Pr(B)$. Bayes\n",
    "rule seems abstract at first, but it can be useful if I am interested\n",
    "in knowing $Pr(A|B)$, and I already have information on $Pr(A|B)$,\n",
    "$Pr(A)$, and $Pr(B)$. It turns out that this could become the case\n",
    "for many statistical inference applications. \n",
    "\n",
    "Similar to the previous unit, suppose, $X=\\left\\{ x_{1},x_{2},x_{3},\\ldots,x_{15}\\right\\} $,\n",
    "is data of $15$ observations generated from a normal distribution\n",
    "with mean $1$ and variance $1$:\n",
    "\\begin{align*}\n",
    "X\\sim & \\boldsymbol{N}(\\mu=1,\\sigma^{2}=1)\n",
    "\\end{align*}\n",
    "As a researcher, I am interested in knowing something about the unknown\n",
    "data generating process. In the previous unit, I was interested in\n",
    "hypothesis testing. Namely, I was interested in knowing if my mean\n",
    "is unequal to a particular hypothesized value. Instead of hypothesis\n",
    "testing, I could be interested in perhaps a more direct approach.\n",
    "Namely, I am interested in learning about what is $\\mu$? Answering\n",
    "the previous question is generally difficult, and maybe impossible.\n",
    "Bayes rule; however, allows me to gain valuable insight on the distribution\n",
    "of $\\mu$ given observed data, $X$. The latter is precisely, $Pr(\\mu|X)$,\n",
    "and can be written with Bayes rule as follows:\n",
    "\\begin{align*}\n",
    "Pr(\\mu|X)= & \\frac{Pr(X|\\mu)Pr(\\mu)}{Pr(X)}\n",
    "\\end{align*}\n",
    "where,\n",
    "\n",
    "$Pr(\\mu|X)$ is the posterior and what Bayes rule will ultimately\n",
    "answer. What is the distribution of $\\mu$ given the drawn data, $X$\n",
    "\n",
    "$Pr(\\mu)$ is the prior. It is the distribution of $\\mu$ independent\n",
    "of any event. Here, we assume $\\mu\\sim\\boldsymbol{N}(\\mu_{0}=1,v_{0}^{2}=1)$\n",
    "\n",
    "$Pr(X|\\mu)$ what is known as the log-likelihood function goes here.\n",
    "What is the probability of obtaining $X$ given a certain mean, $\\mu$.\n",
    "We assume independence between different $X$ values.\n",
    "\n",
    "$Pr(X)$ what is the probability of obtaining $X$ for all possible\n",
    "values of $\\mu$. Integrated in practice over all values of $\\mu$,\n",
    "the term does not depend on the parameters of the models. It is a\n",
    "convention to drop it for simplicity. \n",
    "\n",
    "\\begin{align*}\n",
    "Pr(\\mu|X)\\wasypropto & Pr(X|\\mu)Pr(\\mu)\n",
    "\\end{align*}\n",
    "\n",
    "For simplicity, it is known that $X$ comes from normal with unknown\n",
    "$\\mu$ but known $\\sigma^{2}$. The above more concretely becomes,\n",
    "\\begin{align*}\n",
    "\\xi\\left(\\mu|X\\right)\\wasypropto & f_{n}\\left(X|\\mu\\right)\\xi\\left(\\mu\\right)\n",
    "\\end{align*}\n",
    "\n",
    "where,\n",
    "\n",
    "\\begin{align*}\n",
    "f_{n}\\left(X|\\mu\\right)\\wasypropto & \\exp\\left(\\frac{-1}{2\\sigma^{2}}\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right)\\\\\n",
    "\\\\\n",
    "\\xi\\left(\\mu\\right)\\wasypropto & \\exp\\left(-\\frac{\\left(\\mu-\\mu_{0}\\right)^{2}}{2v_{0}^{2}}\\right)\n",
    "\\end{align*}\n",
    "Given the above, it turns out that,\n",
    "\\begin{align*}\n",
    "\\xi\\left(\\mu|X\\right)\\sim & \\boldsymbol{N}(\\mu_{1},v_{1}^{2})\n",
    "\\end{align*}\n",
    "where,\n",
    "\\begin{align*}\n",
    "\\mu_{1}= & \\frac{\\sigma^{2}\\mu_{0}+nv_{0}^{2}\\bar{x}_{n}}{\\sigma^{2}+nv_{0}^{2}}\\\\\n",
    "\\\\\n",
    "v_{1}^{2}= & \\frac{\\sigma^{2}v_{0}^{2}}{\\sigma^{2}+nv_{0}^{2}}\n",
    "\\end{align*}\n",
    "This can be proved by multiplying $f_{n}\\left(X|\\mu\\right)$ and $\\xi\\left(\\mu\\right)$\n",
    "then substituting in the result. The specific choice of a normal prior\n",
    "makes it conjugate to the normal likelihood function. A conjugate\n",
    "prior ensures a closed solution result with the same family of the\n",
    "prior, namely normal. In more complex applications, a closed form\n",
    "solution is not possible. With the theory on-hand, I will go ahead\n",
    "and demonstrate the example numerically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
